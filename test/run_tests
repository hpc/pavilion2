#!/usr/bin/env python3

import argparse
import os
import shutil
import sys
import unittest
from collections import defaultdict
from pathlib import Path

this_file = Path(__file__).resolve()
lib_dir = this_file.parents[1]/'lib'
tests_dir = this_file.parent/'tests'

# Setup our paths to the pavilion libraries.
sys.path.insert(0, str(lib_dir))

from pavilion import output


def _list_tests(suite):
    """Return a list of tuples of (suite_name, test_name)"""

    tests = []

    if isinstance(suite, unittest.TestSuite):
        for subsuite in suite:
            tests.extend(_list_tests(subsuite))

        return tests

    suite_name = suite.__class__.__name__
    return [(suite_name, suite._testMethodName)]


def list_tests(suite):

    tests = _list_tests(suite)

    by_suite = defaultdict(list)

    for suite_name, test_name in tests:
        if test_name.startswith('test_'):
            test_name = test_name[len('test_'):]
        by_suite[suite_name].append(test_name)

    for suite_name in sorted(by_suite.keys()):
        print('{}:'.format(suite_name))
        for test_name in sorted(by_suite[suite_name]):
            print('  {}'.format(test_name))


try:
    FAILURE_FN = Path('/tmp/.pavilion_run_test_failures_{}.txt'.format(os.getlogin()))
except OSError:
    FAILURE_FN = Path('/tmp/.pavilion_run_test_failures.txt')


def save_failures(failures):
    """Write a list of failed test names to a temp file that we
    can use to re-run just those tests."""


    test_names = []
    for failure in failures:
        failure = failure[0]
        fail_name = '{}.{}'.format(failure.__class__.__name__, 
                                   failure._testMethodName)
        test_names.append(fail_name)

    if test_names:
        pass
        try:
            with FAILURE_FN.open('w') as fail_file:
                for test_name in test_names:
                    fail_file.write(test_name)
                    fail_file.write('\n')
        except OSError:
            pass


def load_failures():
    """Load the list of failures from the failure file."""

    try:
        with FAILURE_FN.open() as fail_file:
            return [fail.strip() for fail in fail_file.readlines() if fail.strip()]
    except OSError:
        return []


def msg(*args, color=output.BLUE, **kwargs):
    """Print a message from the test runner."""

    kwargs['color'] = color
    output.fprint(sys.stderr, *args, **kwargs)


def main():

    from unittest_ex import ColorResult, BetterRunner, TestCaseEx
    from pavilion.unittest import PavTestCase
    from pavilion import log_setup

    config = PavTestCase.TEST_DATA_ROOT/'pav_config_dir'/'pavilion.yaml'
    if not config.exists():
        msg("\nERROR")
        msg("Could not find a config file at '{}'".format(config))
        msg("To run tests, this file must be created.")
        msg("It may be blank, or may contain proxy info.")
        sys.exit(1)

    parser = argparse.ArgumentParser(
        usage="This runs all the tests in the tests/ directory. For a python " 
              "file to be recognized as a test suite, it must end in "
              "'_tests.py'. All other files are ignored")
    parser.add_argument('-l', '--list', action='store_true',
                        help="List the tests, but don't run them.")
    parser.add_argument('-s', '--skip', action='append', default=[],
                        help="Skip tests matching the given glob pattern. The "
                             "'test_' prefix is removed from the name for this "
                             "check.")
    parser.add_argument('-o', '--only', action='append', default=[],
                        help="Only run tests matching the given glob pattern. "
                             "The 'test_' prefix is removed from the name "
                             "for this check.")
    parser.add_argument('--re-run-failures', action='store_true', default=False,
                        help="Only run tests that failed last time.")
    parser.add_argument('-v', '--verbose', action='store_true', default=False,
                        help="Print all log output to stderr.")
    parser.add_argument('-q', '--quiet', action='store_true', default=False,
                        help="Silence.")
    parser.add_argument('-C', '--no-clear', action='store_true', default=False,
                        help="Don't clear the working directory before "
                             "running.")
    args = parser.parse_args(sys.argv[1:])

    if args.skip:
        TestCaseEx.set_skip(args.skip)

    only = args.only
    if args.re_run_failures:
        only += load_failures()
        if not only:
            msg("Selected re-run-failures, but there were no previous failures to re-run.")
            return 0

    if only:
        TestCaseEx.set_only(only)

    working_dir = this_file.parent/'working_dir'
    if not args.list and not args.no_clear and working_dir.exists():
        msg("Clearing out the working directory from prior unit test runs.")

        shutil.rmtree(working_dir.as_posix(), ignore_errors=False)

    log_out = log_setup.setup_loggers(PavTestCase().pav_cfg)

    verbosity = 0 if args.quiet else 2

    loader = unittest.TestLoader()

    msg("Finding all tests.")
    test_pattern = '*_tests.py'
    suite = loader.discover(tests_dir.as_posix(), pattern=test_pattern)

    if args.list:
        list_tests(suite)
        return 0
    else:
        msg("Starting test runs.")

        runner = BetterRunner(resultclass=ColorResult, verbosity=verbosity)
        result = runner.run(suite)

        if args.verbose:
            msg("Log Output")
            msg("--------------------")
            msg(log_out.getvalue())

        save_failures(result.errors + result.failures)

        return len(result.errors) + len(result.failures)


PROFILE = False


if __name__ == '__main__':

    if not PROFILE:
        sys.exit(main())
    else:
        import cProfile
        import pstats
        stats_file = '/tmp/pav_unittest_stats'
        cProfile.run('sys.exit(main())', stats_file)
        stats = pstats.Stats(stats_file)
        print('cumulative')
        stats.sort_stats('cumulative').print_stats(20)
        print('time')
        stats.sort_stats('time').print_stats(20)

