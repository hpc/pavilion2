# YAML        

#   Default test configuration file, vers. 0.3 

# NOTE - all CAPS variable are env vars

#    Each entry can be re-defined by the users test config
#    file with defaults inherited from this file.
#    In theory, the entire default file can be used, but it's recommended
#    at least changing the name, location, and run:cmd sub-elements
#    and then removing everything else you don't need.
#

# for YAML formatting issues try: http://yaml-online-parser.appspot.com
    
# A new named stanza is needed for each new test,
# but you only need to change what's different from the
# this default test_config file

# Default testSuite override. Change even the default file that's used. 
# Uncomment and place in user defined testSuite with
# a fully qualified path/name or just name of the file.
# DefaultTestSuite: default_test_suite.yaml

# Unique (to the test suite being used) test/job identifier. Any string will do.
UniqueTestId:

  name: TestName

  # uri of test, probably a directory name  
  source_location: HOME
        
  # Build Section  
  build:
    # command is relative to source directory
    cmd: 'buildme'
    build_before_run_flag : False
        
  # Run Section 
  run:
    cmd: 'runme'
    # select one scheduler type, or make a new one  
    # choices can be moab, slurm, torque, none  
    scheduler: 'moab'
    # user specified test specific argument string
    test_args: '' 
    # number of times to repeat
    count: 1

  # Optional scheduler section needed if defined in the "run" section
  moab:

    # Parameter(s) provided to scheduler
    # Element stanza corresponds to scheduler choice above.
    # All combinations of <num_nodes> and <procs_per_node> will be
    # tried by by the scheduler where it makes sense. A "none"
    # choice simply invokes the run command once

    # comma separated list of values, or range 
    num_nodes: 1
    # queue to submit jobs against
    queue: '' 
    # comma separated list of values, or range 
    procs_per_node: 16
    # time in hr::min::secs
    time_limit: 01:00:00
    # free formatted string added to msub invocation line
    msub_args:
    # optional target segment, will be added to feature argument
    target_seg: "" 
    # optional list of nodes to target 
    node_list: "" 
    # optional. Percent of cluster consumed by this particular test in this
    # test suite of jobs. Noralization will occurr. 
    percent: ""
    

  # Working space section
  # The default is to create a working space to run each job.
  # If changed to a null value ("") then none created or used, otherwise
  # it should will be relative to the source directory or can be 
  # fully specified directory.

  working_space:
    path: 'pv_ws' 
    copy_to_ws: ''
    save_from_ws: ''
    no_copy: '*.c,*.o,*.h'


  # Results section
  results:

    # The test handler places all results (for this test) under this directory space.
    root: '/Users/cwi/pv_results'

    # Pass or Fail matching pattern
    # the test handler will try to match "<result> pass" or
    # <result> fail" to determine if the test passed or failed.
    pass_fail_regex: '<result\w{0,1}>\s*(.+)'

    # Trend Data matching pattern
    # the test handler will try to match "<td> name value [units]"
    # to discover any special result data  (a.k.a - trend data).
    # The "units" field is optional.
    trend_data_regex: <td>\s+(.*)

    # Script called at the end of the job. By default, the test harness requires
    # a "<result>" entry in the job output located at the beginning of a line
    # followed by a pass or fail. Of course, there are many ways to accomplish this,
    # but if it's not done by the job itself this may be a convient way to post-process 
    # the data and add this entry.
    # *** If define, make sure it's executable  
    epilog_script: "" 

    # Script that contains the logic that examines the job log 
    # to see if the test passed or failed.  chklg reports
    # a fail if there are any "fail" matches with the
    # pass_fail_regex, OR it can report pass if at least one "pass"
    # is matched, otherwise unknown is reported.
    # DO NOT change at this time!
    pass_fail_logic: chklg

  # LDMS tool will use these settings.
  # This tool can generate a great deal of data!
  ldms:
    # used to set env var LDMS_HOME
    install_dir : "/usr/projects/hpctools/ldms"
    # command to start up processes on nodes
    start_cmd: startJobNodesLDMSD
    # root directory where all output will go 
    output_dir_root: HOME 
    # sample rate
    freq: normal
    # comman separated list of plugin sampler names (all coming soon),
    # will be skipped if not supported
    metric_list: "meminfo,vmstat"
    
  time:
    tz: 'US/Mountain'
